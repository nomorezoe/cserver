{   
    "client_id": "test",
    "prompt": {
      "1": {
        "inputs": {
          "a": 6.28,
          "bg_threshold": 0.1,
          "resolution": 512,
          "image": [
            "2",
            0
          ]
        },
        "class_type": "MiDaS-DepthMapPreprocessor"
      },
      "2": {
        "inputs": {
          "image": "8ce985d1-679a-4d42-81c2-d7f8cab3fd0e.png",
          "upload": "image"
        },
        "class_type": "LoadImage"
      },
      "3": {
        "inputs": {
          "images": [
            "1",
            0
          ]
        },
        "class_type": "PreviewImage"
      },
      "4": {
        "inputs": {
          "control_net_name": "control-lora-depth-rank256.safetensors"
        },
        "class_type": "ControlNetLoader"
      },
      "5": {
        "inputs": {
          "strength": 0.53,
          "conditioning": [
            "18",
            0
          ],
          "control_net": [
            "4",
            0
          ],
          "image": [
            "1",
            0
          ]
        },
        "class_type": "ControlNetApply"
      },
      "6": {
        "inputs": {
          "seed": 545136617991141,
          "steps": 20,
          "cfg": 7,
          "sampler_name": "euler",
          "scheduler": "normal",
          "denoise": 1,
          "model": [
            "56",
            0
          ],
          "positive": [
            "5",
            0
          ],
          "negative": [
            "14",
            0
          ],
          "latent_image": [
            "9",
            0
          ]
        },
        "class_type": "KSampler"
      },
      "7": {
        "inputs": {
          "ckpt_name": "dynavisionXL.safetensors"
        },
        "class_type": "CheckpointLoaderSimple"
      },
      "9": {
        "inputs": {
          "width": 1024,
          "height": 1024,
          "batch_size": 4
        },
        "class_type": "EmptyLatentImage"
      },
      "11": {
        "inputs": {
          "samples": [
            "6",
            0
          ],
          "vae": [
            "7",
            2
          ]
        },
        "class_type": "VAEDecode"
      },
      "13": {
        "inputs": {
          "text": [
            "19",
            0
          ],
          "clip": [
            "7",
            1
          ]
        },
        "class_type": "CLIPTextEncode"
      },
      "14": {
        "inputs": {
          "text": [
            "19",
            1
          ],
          "clip": [
            "7",
            1
          ]
        },
        "class_type": "CLIPTextEncode"
      },
      "15": {
        "inputs": {
          "detect_hand": "enable",
          "detect_body": "enable",
          "detect_face": "enable",
          "resolution": 512,
          "bbox_detector": "yolox_l.onnx",
          "pose_estimator": "dw-ll_ucoco_384.onnx",
          "image": [
            "2",
            0
          ]
        },
        "class_type": "DWPreprocessor"
      },
      "16": {
        "inputs": {
          "images": [
            "15",
            0
          ]
        },
        "class_type": "PreviewImage"
      },
      "17": {
        "inputs": {
          "control_net_name": "thibaud_xl_openpose_256lora.safetensors"
        },
        "class_type": "ControlNetLoader"
      },
      "18": {
        "inputs": {
          "strength": 1,
          "conditioning": [
            "13",
            0
          ],
          "control_net": [
            "17",
            0
          ],
          "image": [
            "15",
            0
          ]
        },
        "class_type": "ControlNetApply"
      },
      "19": {
        "inputs": {
          "text_positive": "a lady in the forest",
          "text_negative": "(worst quality, low quality, normal quality, lowres, low details, oversaturated, undersaturated, overexposed, underexposed, grayscale, bw, bad photo, bad photography, bad art:1.4), (watermark, signature, text font, username, error, logo, words, letters, digits, autograph, trademark, name:1.2), (blur, blurry, grainy), morbid, ugly, asymmetrical, mutated malformed, mutilated, poorly lit, bad shadow, draft, cropped, out of frame, cut off, censored, jpeg artifacts, out of focus, glitch, duplicate, (airbrushed, cartoon, anime, semi-realistic, cgi, render, blender, digital art, manga, amateur:1.3), (3D ,3D Game, 3D Game Scene, 3D Character:1.1), (bad hands, bad anatomy, bad body, bad face, bad teeth, bad arms, bad legs, deformities:1.3) horror",
          "style": "base",
          "log_prompt": true
        },
        "class_type": "SDXLPromptStyler"
      },
      "51": {
        "inputs": {
          "ipadapter_file": "ip-adapter_sdxl.bin"
        },
        "class_type": "IPAdapterModelLoader"
      },
      "54": {
        "inputs": {
          "clip_name": "model.safetensors"
        },
        "class_type": "CLIPVisionLoader"
      },
      "55": {
        "inputs": {
          "image": "ComfyUI_01605_.png",
          "upload": "image"
        },
        "class_type": "LoadImage"
      },
      "56": {
        "inputs": {
          "weight": 1,
          "noise": 0,
          "weight_type": "original",
          "start_at": 0,
          "end_at": 1,
          "unfold_batch": false,
          "ipadapter": [
            "51",
            0
          ],
          "clip_vision": [
            "54",
            0
          ],
          "image": [
            "58",
            0
          ],
          "model": [
            "7",
            0
          ]
        },
        "class_type": "IPAdapterApply"
      },
      "57": {
        "inputs": {
          "filename_prefix": "ComfyUI",
          "images": [
            "11",
            0
          ]
        },
        "class_type": "SaveImage"
      },
      "58": {
        "inputs": {
          "interpolation": "LANCZOS",
          "crop_position": "top",
          "sharpening": 0,
          "image": [
            "55",
            0
          ]
        },
        "class_type": "PrepImageForClipVision"
      }
    }
}