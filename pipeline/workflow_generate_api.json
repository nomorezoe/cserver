{   "client_id": "test",
    "prompt": {
        "1": {
            "inputs": {
                "a": 6.283185307179586,
                "bg_threshold": 0.1,
                "resolution": 512,
                "image": [
                    "2",
                    0
                ]
            },
            "class_type": "MiDaS-DepthMapPreprocessor"
        },
        "2": {
            "inputs": {
                "image": "8ce985d1-679a-4d42-81c2-d7f8cab3fd0e.png",
                "upload": "image"
            },
            "class_type": "LoadImage"
        },
        "3": {
            "inputs": {
                "images": [
                    "1",
                    0
                ]
            },
            "class_type": "PreviewImage"
        },
        "4": {
            "inputs": {
                "control_net_name": "controlnetxlCNXL_saiDepth.safetensors"
            },
            "class_type": "ControlNetLoader"
        },
        "5": {
            "inputs": {
                "strength": 1,
                "conditioning": [
                    "18",
                    0
                ],
                "control_net": [
                    "4",
                    0
                ],
                "image": [
                    "1",
                    0
                ]
            },
            "class_type": "ControlNetApply"
        },
        "6": {
            "inputs": {
                "seed": 279629809467275,
                "steps": 20,
                "cfg": 8,
                "sampler_name": "euler",
                "scheduler": "normal",
                "denoise": 1,
                "model": [
                    "7",
                    0
                ],
                "positive": [
                    "5",
                    0
                ],
                "negative": [
                    "14",
                    0
                ],
                "latent_image": [
                    "9",
                    0
                ]
            },
            "class_type": "KSampler"
        },
        "7": {
            "inputs": {
                "ckpt_name": "dynavisionXL.safetensors"
            },
            "class_type": "CheckpointLoaderSimple"
        },
        "9": {
            "inputs": {
                "width": 512,
                "height": 512,
                "batch_size": 4
            },
            "class_type": "EmptyLatentImage"
        },
        "11": {
            "inputs": {
                "samples": [
                    "6",
                    0
                ],
                "vae": [
                    "7",
                    2
                ]
            },
            "class_type": "VAEDecode"
        },
        "12": {
            "inputs": {
                "filename_prefix": "ComfyUI",
                "images": [
                    "11",
                    0
                ]
            },
            "class_type": "SaveImage"
        },
        "13": {
            "inputs": {
                "text": "a lady in the forest",
                "clip": [
                    "7",
                    1
                ]
            },
            "class_type": "CLIPTextEncode"
        },
        "14": {
            "inputs": {
                "text": "(worst quality, low quality, normal quality, lowres, low details, oversaturated, undersaturated, overexposed, underexposed, grayscale, bw, bad photo, bad photography, bad art:1.4), (watermark, signature, text font, username, error, logo, words, letters, digits, autograph, trademark, name:1.2), (blur, blurry, grainy), morbid, ugly, asymmetrical, mutated malformed, mutilated, poorly lit, bad shadow, draft, cropped, out of frame, cut off, censored, jpeg artifacts, out of focus, glitch, duplicate, (airbrushed, cartoon, anime, semi-realistic, cgi, render, blender, digital art, manga, amateur:1.3), (3D ,3D Game, 3D Game Scene, 3D Character:1.1), (bad hands, bad anatomy, bad body, bad face, bad teeth, bad arms, bad legs, deformities:1.3) horror",
                "clip": [
                    "7",
                    1
                ]
            },
            "class_type": "CLIPTextEncode"
        },
        "15": {
            "inputs": {
                "detect_hand": "enable",
                "detect_body": "enable",
                "detect_face": "enable",
                "resolution": 512,
                "bbox_detector": "yolox_l.onnx",
                "pose_estimator": "dw-ll_ucoco_384.onnx",
                "image": [
                    "2",
                    0
                ]
            },
            "class_type": "DWPreprocessor"
        },
        "16": {
            "inputs": {
                "images": [
                    "15",
                    0
                ]
            },
            "class_type": "PreviewImage"
        },
        "17": {
            "inputs": {
                "control_net_name": "thibaud_xl_openpose_256lora.safetensors"
            },
            "class_type": "ControlNetLoader"
        },
        "18": {
            "inputs": {
                "strength": 1,
                "conditioning": [
                    "13",
                    0
                ],
                "control_net": [
                    "17",
                    0
                ],
                "image": [
                    "15",
                    0
                ]
            },
            "class_type": "ControlNetApply"
        }
    }
}